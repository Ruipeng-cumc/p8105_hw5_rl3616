---
title: "p8105_hw5_rl3616"
author: "Ruipeng Li"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
set.seed(123) 
```

### Problem 1

```{r}
has_duplicate_birthday <- function(n) {
  b <- sample(1:365, size = n, replace = TRUE)
  any(duplicated(b))
  }
group_size = 2:50
n_sim = 10000

birthday_results <- map_df(
  group_size,
  ~ tibble(
    n = .x, 
    dup = replicate(n_sim, has_duplicate_birthday(.x))
    )
  )

prob_by_n <- birthday_results |>
  group_by(n) |> 
  summarise(prob_dup = mean(dup), .groups = "drop")

prob_by_n
```

```{r}
ggplot(prob_by_n, aes(x = n, y = prob_dup)) +
  geom_line() +
  geom_point() +
  labs(
    x = "Group size (n)",
    y = "P(at least two share a birthday)",
    title = "Birthday Duplicate Simulation"
    ) +
  theme_minimal()
```  
As shown in the plot, when the group size is very small, the probability of having a shared birthday is close to zero. As the group size increases, the probability rises rapidly. Around a group size of 25, the rate of increase begins to slow down, and eventually the probability approaches 100%.

### Problem 2

```{r}
n <- 30
sigma <- 5
n_sim <- 5000
mu_vec <- 0:6

sim_one_mu <- function(mu, n = 30, sigma = 5, n_sim = 5000) {
  
  map(1:n_sim, ~{
    x <- rnorm(n, mean = mu, sd = sigma)
    
    t_tidy <- broom::tidy(t.test(x, mu = 0))
    
    tibble(
      mu_true = mu,
      mu_hat = t_tidy$estimate,
      p_value = t_tidy$p.value
    )
  }) |> 
    list_rbind()
}

mu_sim_results <- map_df(mu_vec, sim_one_mu)

mu_sim_results
```

#### Proportion of times the null was rejected

```{r}
power_by_mu <- mu_sim_results |>
  group_by(mu_true) |>
  summarise(
    power = mean(p_value < 0.05),
    .groups = "drop"
  )

power_by_mu

rej_prop_plot <- power_by_mu |> 
  ggplot(aes(x = mu_true, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean μ",
    y = "Proportion of reject H0",
    title = "Power of one-sample t-test vs effect size"
  ) +
  ylim(0,1)

rej_prop_plot
  
```

When μ = 0, H₀ is true, and the rejection rate is approximately 0.05 (which is α).

The further μ is from 0 (in this case, increasing in the positive direction), the larger the effect size, the easier it is for the t-test to detect differences, and the higher the power until it reach to 1.

#### μ estimate plot

```{r}
mu_hat_avg <- mu_sim_results |> 
  group_by(mu_true) |> 
  summarise(
    mean_mu_hat_avg = mean(mu_hat),
    .groups = "drop"
  )

mu_hat_rej <- mu_sim_results |> 
  filter(p_value < 0.5) |> 
  group_by(mu_true) |> 
  summarise(
    mean_mu_hat_rej = mean(mu_hat),
    .groups = "drop"
  )

mu_estimate_plot <- mu_hat_avg |> 
  left_join(mu_hat_rej, by = "mu_true") |> 
  ggplot(aes(x = mu_true)) +
    geom_line(aes(y = mean_mu_hat_avg, color = "All samples")) +
    geom_point(aes(y = mean_mu_hat_avg, color = "All samples")) +
    geom_line(aes(y = mean_mu_hat_rej, color = "Only significant (p < 0.05)")) +
    geom_point(aes(y = mean_mu_hat_rej, color = "Only significant (p < 0.05)")) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    labs(
      x = "True mean μ",
      y = "Average of μ̂",
      color = "",
      title = "Average estimate vs true μ"
    )

mu_estimate_plot
```   
Across all samples, the average sample mean (μ̂) is approximately equal to the true μ, so the red line roughly falls on y=x.

However, if we only consider samples with p < 0.05, only the samples with "larger differences" are retained, while samples with smaller differences are excluded.

This causes the μ̂ of the retained samples to tend to be slightly larger than the true μ, so the blue line will appear on y=x, especially when the true μ is relatively small.

### Problem 3
```{r}
homicides <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicides_df <- homicides |> 
  janitor::clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state)
  ) |> 
  group_by(city_state) |> 
  summarise(
    total = n(),
    n_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  )
```

#### Prop.test for Baltimore, MD  
```{r}
baltimore_homicides <- homicides_df |> 
  filter(city_state == "Baltimore, MD") 

baltimore_test <- prop.test(
    x = baltimore_homicides$n_unsolved,
    n = baltimore_homicides$total
  ) |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high)
```

#### Prop.test for all
```{r}
city_test <- homicides_df |> 
  mutate(
    prop_test = map2(n_unsolved, total, 
                     ~ broom::tidy(prop.test(.x, .y)))
  ) |> 
  unnest(prop_test) |> 
  select(city_state, total, n_unsolved, estimate, conf.low, conf.high)
  
city_pt <- city_test |> 
  filter(total >= 10) |> 
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state)) |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    x = "City",
    y = "Proportion unsolved (95% CI)",
    title = "Estimated Proportion of Unsolved Homicides by City"
  )

city_pt

```   
Note: Tulsa, AL had only one homicide in the dataset. Because of the extremely small sample size, the corresponding confidence interval spans nearly the entire range and provides little interpretive value. For this reason, I removed Tulsa, AL from the visualization to improve readability.
